{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchmetrics import Dice\n",
    "from torchvision.transforms import Resize, RandomCrop\n",
    "from torchvision.transforms.functional import crop\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVIDDataset4K(Dataset):\n",
    "    def __init__(self, path, is_train=True):\n",
    "        directory = Path(path)\n",
    "        if is_train:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_train/**/Images/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_train/**/Labels/*.png\")\n",
    "            ]\n",
    "        else:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_val/**/Images/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"uavid_val/**/Labels/*.png\")\n",
    "            ]\n",
    "\n",
    "        if len(self.images) is not len(self.labels):\n",
    "            print(\"Number of images & label are not the same.\")\n",
    "            return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_image(image_path):\n",
    "        return read_image(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_image(image):\n",
    "        resizer = Resize([2160, 3840], antialias=\"True\")\n",
    "        return resizer(image)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_0and1(label):\n",
    "        return label.type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_0and1(image):\n",
    "        return (image / 255).type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_label(label):\n",
    "        labels = []\n",
    "        labels.append((label[0] == 0) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 64) & (label[2] == 128))\n",
    "        labels.append((label[0] == 0) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 64) & (label[1] == 0) & (label[2] == 128))\n",
    "        labels.append((label[0] == 192) & (label[1] == 0) & (label[2] == 192))\n",
    "        labels.append((label[0] == 64) & (label[1] == 64) & (label[2] == 0))\n",
    "        return torch.stack(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.decode_image(self.images[index])\n",
    "        image = self.resize_image(image)\n",
    "        image = self.image_0and1(image)\n",
    "\n",
    "        label = self.decode_image(self.labels[index])\n",
    "        label = self.resize_image(label)\n",
    "        label = self.label_0and1(label)\n",
    "        label = self.mask_label(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVIDDataset(Dataset):\n",
    "    def __init__(self, path, is_train=True):\n",
    "        directory = Path(path)\n",
    "        if is_train:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"train/image/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"train/label/*.png\")\n",
    "            ]\n",
    "        else:\n",
    "            self.images = [\n",
    "                str(x.absolute()) for x in directory.glob(\"test/image/*.png\")\n",
    "            ]\n",
    "            self.labels = [\n",
    "                str(x.absolute()) for x in directory.glob(\"test/label/*.png\")\n",
    "            ]\n",
    "\n",
    "        if len(self.images) != len(self.labels):\n",
    "            print(\"Number of images & label are not the same.\")\n",
    "            return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_image(image_path):\n",
    "        return read_image(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_image(image):\n",
    "        resizer = Resize([2160, 3840], antialias=\"True\")\n",
    "        return resizer(image)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_0and1(label):\n",
    "        return label.type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_0and1(image):\n",
    "        return (image / 255).type(torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_label(label):\n",
    "        labels = []\n",
    "        labels.append((label[0] == 0) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 0) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 64) & (label[2] == 128))\n",
    "        labels.append((label[0] == 0) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 128) & (label[1] == 128) & (label[2] == 0))\n",
    "        labels.append((label[0] == 64) & (label[1] == 0) & (label[2] == 128))\n",
    "        labels.append((label[0] == 192) & (label[1] == 0) & (label[2] == 192))\n",
    "        labels.append((label[0] == 64) & (label[1] == 64) & (label[2] == 0))\n",
    "        return torch.stack(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.decode_image(self.images[index])\n",
    "        i, j, h, w = RandomCrop.get_params(image, (256, 256))\n",
    "        image = self.image_0and1(image)\n",
    "        label = self.decode_image(self.labels[index])\n",
    "        label = self.mask_label(label)\n",
    "        label = self.label_0and1(label)\n",
    "\n",
    "        # Crop image and label\n",
    "        image = crop(image, i, j, h, w)\n",
    "        label = crop(label, i, j, h, w)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = UAVIDDataset4K(path=\"data/uavid_v1.5_official_release_image\", is_train=True)\n",
    "training_data = UAVIDDataset(path=\"data/processed_dataset/\", is_train=True)\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "train_feature, train_label = next(iter(train_dataloader))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(torch.permute(train_feature[0], [1, 2, 0]))\n",
    "\n",
    "figure, axes = plt.subplots(8, 1, figsize=(9, 16))\n",
    "for i in range(8):\n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].imshow(\n",
    "        torch.permute(train_label, [0, 2, 3, 1]).numpy()[0, ..., i],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNETNetwork(nn.Module):\n",
    "    def __init__(self, numberClass):\n",
    "        super().__init__()\n",
    "        _resnet50 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backbone = create_feature_extractor(\n",
    "            _resnet50,\n",
    "            {\n",
    "                \"relu\": \"feat1\",\n",
    "                \"layer1\": \"feat2\",\n",
    "                \"layer2\": \"feat3\",\n",
    "                \"layer3\": \"feat4\",\n",
    "                \"layer4\": \"feat5\",\n",
    "            },\n",
    "        )\n",
    "        self.upsample2x1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.upsample2x2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.upsample2x3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.upsample2x4 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.upsample2x5 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=2048,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=1280,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=768,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=512,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.relu8 = nn.ReLU()\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=320,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.relu9 = nn.ReLU()\n",
    "        self.convfinal = nn.Conv2d(\n",
    "            in_channels=256,\n",
    "            out_channels=numberClass,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        self.final_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        backbone_output = self.backbone(x)\n",
    "        feat1, feat2, feat3, feat4, feat5 = (\n",
    "            backbone_output[\"feat1\"],\n",
    "            backbone_output[\"feat2\"],\n",
    "            backbone_output[\"feat3\"],\n",
    "            backbone_output[\"feat4\"],\n",
    "            backbone_output[\"feat5\"],\n",
    "        )\n",
    "        feat4to6 = self.upsample2x1(self.relu5(self.conv5(feat5)))\n",
    "        feat3to7 = self.upsample2x2(\n",
    "            self.relu6(self.conv6(torch.concat([feat4, feat4to6], dim=1)))\n",
    "        )\n",
    "        feat2to8 = self.upsample2x3(\n",
    "            self.relu7(self.conv7(torch.concat([feat3, feat3to7], dim=1)))\n",
    "        )\n",
    "        feat1to9 = self.upsample2x4(\n",
    "            self.relu8(self.conv8(torch.concat([feat2, feat2to8], dim=1)))\n",
    "        )\n",
    "        featout = self.upsample2x5(\n",
    "            self.relu9(self.conv9(torch.concat([feat1, feat1to9], dim=1)))\n",
    "        )\n",
    "        return self.final_activation(self.convfinal(featout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = UAVIDDataset(path=\"data/processed_dataset/\", is_train=True)\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "loss_fn1 = torch.nn.CrossEntropyLoss().to(\"mps\")\n",
    "loss_fn2 = Dice().to(\"mps\")\n",
    "model = UNETNetwork(numberClass=8).to(\"mps\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "\n",
    "def loss_fn(outputs, labels):\n",
    "    return loss_fn1(outputs, labels) + (1 - loss_fn2(outputs, labels.to(torch.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs: torch.Tensor\n",
    "        labels: torch.Tensor\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(\"mps\")\n",
    "        labels = labels.to(\"mps\")\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 500 == 499:\n",
    "            print(f\"Loss: {running_loss / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(train_feature.to(\"mps\"))\n",
    "    outputs = outputs.to(\"cpu\")\n",
    "    figure, axes = plt.subplots(8, 2, figsize=(9, 9))\n",
    "    for i in range(8):\n",
    "        axes[i, 0].set_axis_off()\n",
    "        axes[i, 0].imshow(\n",
    "            torch.permute(train_label, [0, 2, 3, 1]).numpy()[1, ..., i],\n",
    "            cmap=\"gray\",\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )\n",
    "        axes[i, 1].set_axis_off()\n",
    "        axes[i, 1].imshow(\n",
    "            torch.permute(outputs, [0, 2, 3, 1]).numpy()[1, ..., i],\n",
    "            cmap=\"gray\",\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.permute(train_feature, [0, 2, 3, 1])[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
